{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZSbdEFMWRm0",
        "outputId": "85a84c82-9010-426f-f0c6-bf2bd1d3e319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (2.12.5)\n",
            "Requirement already satisfied: sniffio in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\piyus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
            "[notice] To update, run: C:\\Users\\piyus\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HAxamFUQW5_Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fu1LIW-XTFF"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4ZoM06CmeqrL"
      },
      "outputs": [],
      "source": [
        "# gpt-4o-2024-08-06"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SMmgRK4wXxSF"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert AI assistant specializing in artificial intelligence, machine learning, and deep learning. Answer questions accurately, concisely, and with practical examples where helpful. Use technical depth appropriate to the user's question.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"how can i fill the gap in AI about LLM contex undestanding not about contex windows?\"\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KovUeLpsW-zR",
        "outputId": "a52775d3-f91e-41bc-8d6f-5170b6e9abb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filling the gap in LLM contextual understanding—beyond just extending context window sizes—requires advancing how models interpret, reason about, and utilize context. Here are several strategies:\n",
            "\n",
            "1. **Enhance Model Architectures for Deeper Understanding:**\n",
            "   - **Incorporate Explicit Reasoning Modules:** Integrate modules like symbolic reasoning or memory-augmented architectures (e.g., Neural Turing Machines, Differentiable Neural Computers) that allow models to manipulate and reason over structured data or long-term information.\n",
            "   - **Improve Multi-Hop Reasoning:** Design models capable of multi-step inference, such as incorporating graph neural networks or iterative attention mechanisms that can connect related facts across the context.\n",
            "\n",
            "2. **Structured and Hierarchical Context Modeling:**\n",
            "   - **Hierarchical Attention:** Implement attention mechanisms that operate at multiple levels—sentence, paragraph, document—to better capture the structure and relationships within longer texts.\n",
            "   - **Auxiliary Tasks for Context Comprehension:** Use pretraining objectives that promote understanding of document structure, logical flow, and causal relationships.\n",
            "\n",
            "3. **Memory and Retrieval-Augmented Techniques:**\n",
            "   - **External Knowledge Bases or Databases:** Combine LLMs with retrieval systems that fetch relevant information dynamically, effectively expanding context understanding without increasing window size.\n",
            "   - **Memory-Augmented Transformers:** Use models with explicit memory components that store and retrieve contextual information over longer periods.\n",
            "\n",
            "4. **Fine-Grained Annotations and Supervised Signals:**\n",
            "   - **Supervised Fine-tuning:** Use datasets that require reasoning, summarization, or question answering to push models toward deeper comprehension.\n",
            "   - **Contrastive Learning or Explanation Generation:** Encourage models to generate explanations or contrast different pieces of information to reinforce understanding.\n",
            "\n",
            "5. **Training Data and Corpus Design:**\n",
            "   - Curate training corpora that emphasize logical structure, cause-effect relations, and reasoning examples, helping models learn to understand context rather than just memorize patterns.\n",
            "\n",
            "**Practical Example:**  \n",
            "Implementing a retrieval-augmented generation system where, during inference, the model retrieves relevant documents from an external corpus based on the input query, then conditions its response on this extended context. This allows the model to \"understand\" and reason over a much larger body of knowledge than its fixed context window permits.\n",
            "\n",
            "**In summary:**  \n",
            "Addressing AI's gap in understanding context involves architectural innovations, leveraging external memory and retrieval, designing better training curricula, and adopting hierarchical and reasoning-focused models—not just expanding context window size.\n"
          ]
        }
      ],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DqzG8HKeX4WQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"data2.jsonl\",\"r\",encoding=\"utf-8\") as file:\n",
        "  data=[json.loads(line) for line in file]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\\\\\Project\\\\\\\\LLM_FINETUNING_OPENAI\\\\\\\\data2.jsonl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2682513140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"c:\\\\Project\\\\LLM_FINETUNING_OPENAI\\\\data2.jsonl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\\\\\Project\\\\\\\\LLM_FINETUNING_OPENAI\\\\\\\\data2.jsonl'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ff66MFHceZR",
        "outputId": "ca52990d-c4e1-4fcc-fcd8-72f4645cef5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'How long does the warranty last on a new smartphone?'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'Can I use the same apps on Android and iPhone?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Not all apps are available on both platforms. Some apps are exclusive to either Android or iOS, depending on the app store.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'How often do smartphones receive software updates?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Software update frequency depends on the manufacturer and model. Supported devices usually receive updates regularly.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'My phone battery drains very quickly. What should I do?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Battery drain can occur due to heavy usage or background apps. Checking battery settings and usage details may help identify the cause.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user', 'content': 'Where can I get my smartphone repaired?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'You can request a repair through the official support website or visit an authorized service center.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'Are there discounts available during festival sales?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Discounts vary by region and time. Please check the official website or promotional announcements for accurate information.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user', 'content': 'Can I expand the storage on my smartphone?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Storage expansion depends on the model. Some smartphones support microSD cards, while others do not.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user', 'content': 'Is my smartphone waterproof?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Some smartphones offer water resistance, but this varies by model. Please check the device specifications for the official rating.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user', 'content': 'Can you recommend a good laptop for work?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'I’m here to assist only with smartphone-related questions. For laptops, please consult the appropriate product support resources.'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              "   {'role': 'user', 'content': 'What happens if I factory reset my phone?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'A factory reset removes all personal data and restores the phone to its original settings. Please back up important data before proceeding.'}]}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVC0wfNO7SdT"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# with open(\"/content/data_error.jsonl\",\"r\",encoding=\"utf-8\") as file:\n",
        "#   data_error=[json.loads(line) for line in file]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAtIi4wRcfEv",
        "outputId": "41c2467e-8dcc-4244-d273-b21b2acfebe1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'user',\n",
              " 'content': 'How long does the warranty last on a new smartphone?'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data[0]['messages'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9fDw_0-e5xa",
        "outputId": "f61a57bd-d490-4467-85af-b84671873b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 10\n",
            "First example:\n",
            "{'role': 'system', 'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'}\n",
            "{'role': 'user', 'content': 'How long does the warranty last on a new smartphone?'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Num examples:\", len(data))\n",
        "print(\"First example:\")\n",
        "for message in data[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAOWTquw5-lq"
      },
      "source": [
        "“We use defaultdict so our error counters start from zero automatically and never crash.”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iCYQhdu2PFNO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "sgWLriaNpw1Q",
        "outputId": "51e587ec-cc19-4011-a3b2-ffd29b21760a"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'apple'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m counts = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#counts[\"apple\"] = counts[\"apple\"] + 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mcounts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapple\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m += \u001b[32m1\u001b[39m   \u001b[38;5;66;03m# ❌ ERROR\u001b[39;00m\n",
            "\u001b[31mKeyError\u001b[39m: 'apple'"
          ]
        }
      ],
      "source": [
        "counts = {}\n",
        "\n",
        "#counts[\"apple\"] = counts[\"apple\"] + 1\n",
        "counts[\"apple\"] += 1   # ❌ ERROR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XL56QNIGps5b"
      },
      "outputs": [],
      "source": [
        "counts = {}\n",
        "counts[\"apple\"] = 0\n",
        "\n",
        "\n",
        "counts[\"apple\"] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3aC8OKPpyVr",
        "outputId": "d3d79f5c-d3fb-476c-f88a-5e21228cf66a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'apple': 1}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S_tcEQ4dqRaa"
      },
      "outputs": [],
      "source": [
        "counts = defaultdict(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "o-ZvrcTPqndQ"
      },
      "outputs": [],
      "source": [
        "counts[\"apple\"] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0yv5AiBquS3",
        "outputId": "db556ae6-9f46-4cc3-e235-74601df80c2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {'apple': 1})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ps2JFxXBqv0W"
      },
      "outputs": [],
      "source": [
        "counts[\"banana\"] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUjkitIqxO7",
        "outputId": "72fddc46-5380-438f-c22d-4358d0da00b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {'apple': 1, 'banana': 1})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZrJKJ9n7q0h9"
      },
      "outputs": [],
      "source": [
        "counts[\"apple\"] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD11-Cv6q1My",
        "outputId": "d853eb4d-9c95-4d2a-840c-3f5ada9b9875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'apple': 2, 'banana': 1})\n"
          ]
        }
      ],
      "source": [
        "print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5jrotc6e7rR"
      },
      "source": [
        "# Format validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOcxC0Ba9Kbt"
      },
      "source": [
        "| # | Validation Check         | Code Condition                    | What It Ensures                        | Error Key Raised                    |\n",
        "| - | ------------------------ | --------------------------------- | -------------------------------------- | ----------------------------------- |\n",
        "| 1 | Example type             | `isinstance(ex, dict)`            | Each JSONL line is a valid JSON object | `data_type`                         |\n",
        "| 2 | `messages` key exists    | `ex.get(\"messages\")`              | Conversation structure is present      | `missing_messages_list`             |\n",
        "| 3 | Required keys in message | `\"role\"` and `\"content\"`          | Every message follows chat format      | `message_missing_key`               |\n",
        "| 4 | No extra keys            | Allowed keys only                 | Prevents unsupported fields            | `message_unrecognized_key`          |\n",
        "| 5 | Valid role names         | `system/user/assistant/function`  | No invalid or typo roles               | `unrecognized_role`                 |\n",
        "| 6 | Valid content            | Non-empty string or function_call | Message text is usable                 | `missing_content`                   |\n",
        "| 7 | Assistant present        | At least one `assistant` role     | Supervised learning signal exists      | `example_missing_assistant_message` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pl165e3yq7zr"
      },
      "outputs": [],
      "source": [
        "format_errors = defaultdict(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktYN2ybjex-A",
        "outputId": "37353a88-d2e2-467d-e39e-093a5cafb8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found errors:\n",
            "example_missing_assistant_message: 1\n"
          ]
        }
      ],
      "source": [
        "for ex in data:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pusZXXe-fAOv"
      },
      "source": [
        "# Token Counting Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA0TB7by91CY"
      },
      "source": [
        "Ye code fine-tuning se pehle tumhare dataset ka “health check” karta hai — structure, size, aur token safety."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkMDf8P29oVM"
      },
      "source": [
        "| Function                             | Kaam                                                     |\n",
        "| ------------------------------------ | -------------------------------------------------------- |\n",
        "| `num_tokens_from_messages`           | Ek full conversation ke **total tokens** count karta hai |\n",
        "| `num_assistant_tokens_from_messages` | Sirf **assistant ke answer tokens** count karta hai      |\n",
        "| `print_distribution`                 | Token/message ka **statistical summary** print karta hai |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4MVLQiW9wwN"
      },
      "source": [
        "| Check                  | Kya ensure karta hai      |\n",
        "| ---------------------- | ------------------------- |\n",
        "| system message present | Persona & behavior locked |\n",
        "| user message present   | Input exists              |\n",
        "| message count          | Conversation structure    |\n",
        "| total tokens           | Cost + truncation risk    |\n",
        "| assistant tokens       | Answer length control     |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXg_uI2A-JrY"
      },
      "source": [
        "| Aspect          | Status    |\n",
        "| --------------- | --------- |\n",
        "| Format          | ✅ Perfect |\n",
        "| Persona         | ✅ Stable  |\n",
        "| Token size      | ✅ Safe    |\n",
        "| Cost            | ✅ Low     |\n",
        "| Truncation risk | ❌ None    |\n",
        "| SFT ready       | ✅ Yes     |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "B-FsuXmFSIcy"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Encoding 'cl100k_base'>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Tp7_diR7uEd-"
      },
      "outputs": [],
      "source": [
        "text = \"what is AGI?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy2ZOViQudYn",
        "outputId": "f20fd1b3-509a-49a7-a9af-936c85eeea64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3osE4C3qupgY",
        "outputId": "f75be4b2-2dd9-466d-e46a-6d4f1fe04e30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what', 'is', 'AGI?']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVnuHg3AuVEN",
        "outputId": "7aa80cdd-5179-4b9f-9178-fd373af524a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RG6YtQHsuuFz"
      },
      "outputs": [],
      "source": [
        "token_ids=encoding.encode(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4YU6XKHwlQP"
      },
      "source": [
        "| Token   | Token ID |\n",
        "| ------- | -------- |\n",
        "| \"Hello\" | 9906     |\n",
        "| \",\"     | 11       |\n",
        "| \" how\"  | 1268     |\n",
        "| \" are\"  | 527      |\n",
        "| \" you\"  | 499      |\n",
        "| \"?\"     | 30       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmYmmVb7wZMR",
        "outputId": "de4163e9-eb27-49dc-cd45-c67b4a9b9b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is AGI?\n"
          ]
        }
      ],
      "source": [
        "decoded_text = encoding.decode(token_ids)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a customer support assistant for a smartphone company. You are friendly, concise, and provide only factual answers related to smartphones.'},\n",
              " {'role': 'user',\n",
              "  'content': 'How long does the warranty last on a new smartphone?'}]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0]['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dzec4mBth3L"
      },
      "outputs": [],
      "source": [
        "# def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "#     num_tokens = 0\n",
        "#     for message in messages:\n",
        "#         num_tokens += tokens_per_message\n",
        "#         for key, value in message.items():\n",
        "#             num_tokens += len(encoding.encode(value))\n",
        "#             if key == \"name\":\n",
        "#                 num_tokens += tokens_per_name\n",
        "#     num_tokens += 3\n",
        "#     return num_tokens\n",
        "\n",
        "# def num_assistant_tokens_from_messages(messages):\n",
        "#     num_tokens = 0\n",
        "#     for message in messages:\n",
        "#         if message[\"role\"] == \"assistant\":\n",
        "#             num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "#     return num_tokens\n",
        "\n",
        "# def print_distribution(values, name):\n",
        "#     print(f\"\\n#### Distribution of {name}:\")\n",
        "#     print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "#     print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "#     print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "# # Warnings and tokens counts\n",
        "# n_missing_system = 0\n",
        "# n_missing_user = 0\n",
        "# n_messages = []\n",
        "# convo_lens = []\n",
        "# assistant_message_lens = []\n",
        "\n",
        "# for ex in data:\n",
        "#     messages = ex[\"messages\"]\n",
        "#     if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "#         n_missing_system += 1\n",
        "#     if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "#         n_missing_user += 1\n",
        "#     n_messages.append(len(messages))\n",
        "#     convo_lens.append(num_tokens_from_messages(messages))\n",
        "#     assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "# print(\"Num examples missing system message:\", n_missing_system)\n",
        "# print(\"Num examples missing user message:\", n_missing_user)\n",
        "# print_distribution(n_messages, \"num_messages_per_example\")\n",
        "# print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "# print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "# n_too_long = sum(l > 16385 for l in convo_lens)\n",
        "# print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "o9bc_T9ZXeXx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "total_tokens = []\n",
        "assistant_tokens = []\n",
        "\n",
        "def count_total_tokens(messages):\n",
        "    return sum(len(encoding.encode(m[\"content\"])) for m in messages)\n",
        "\n",
        "def count_assistant_tokens(messages):\n",
        "    return sum(\n",
        "        len(encoding.encode(m[\"content\"]))\n",
        "        for m in messages\n",
        "        if m[\"role\"] == \"assistant\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WGDjRxR26jeO"
      },
      "outputs": [],
      "source": [
        "for ex in data:\n",
        "    messages = ex[\"messages\"]\n",
        "    total_tokens.append(count_total_tokens(messages))\n",
        "    assistant_tokens.append(count_assistant_tokens(messages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwT8PVML6kQ8",
        "outputId": "ccab0f25-53f9-49ed-e293-2129979e6513"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[37, 62, 51, 62, 51, 54, 54, 53, 57, 59]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjc0qT7F6lxn",
        "outputId": "34357a12-4977-475f-dad5-e641b2678d24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 25, 17, 24, 17, 20, 19, 22, 22, 24]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA7uA1r36p2j",
        "outputId": "591f71a7-94dc-45e0-89ec-d0a752d0bcb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg total tokens per example: 54\n",
            "Max total tokens per example: 62\n"
          ]
        }
      ],
      "source": [
        "print(\"Avg total tokens per example:\", int(np.mean(total_tokens)))\n",
        "print(\"Max total tokens per example:\", max(total_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slx3uRk36tC1",
        "outputId": "aed5803b-d293-422c-b2a6-5db2a1135a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg assistant tokens: 19\n",
            "Max assistant tokens: 25\n"
          ]
        }
      ],
      "source": [
        "print(\"Avg assistant tokens:\", int(np.mean(assistant_tokens)))\n",
        "print(\"Max assistant tokens:\", max(assistant_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18QYrvaNfJKM"
      },
      "source": [
        "# Cost Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v5yOcrC-2zo"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfYlaw0MAqR0"
      },
      "source": [
        "| Parameter             | Value           | Meaning (Simple)                                         | Why It Exists                                              |\n",
        "| --------------------- | --------------- | -------------------------------------------------------- | ---------------------------------------------------------- |\n",
        "| `TARGET_EPOCHS`       | `3`             | Default training passes (dataset ko 3 baar repeat karna) | Balanced learning: na kam, na zyada                        |\n",
        "| `MIN_TARGET_EXAMPLES` | `100`           | Minimum total training examples (examples × epochs)      | Chhote dataset me enough learning ensure karne ke liye     |\n",
        "| `MAX_TARGET_EXAMPLES` | `25000`         | Maximum total training examples                          | Bahut bade dataset me cost explode hone se bachane ke liye |\n",
        "| `MIN_DEFAULT_EPOCHS`  | `1`             | Minimum allowed epochs                                   | Kam se kam ek full pass toh ho                             |\n",
        "| `MAX_DEFAULT_EPOCHS`  | `25`            | Maximum allowed epochs                                   | Overfitting + zyada cost se bachav                         |\n",
        "| `n_epochs`            | `TARGET_EPOCHS` | Final epochs (start me default = 3)                      | Baad me dataset size dekh kar adjust hota hai              |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LmPnIjuFJaz2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16385"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#EXAMPLE\n",
        "\n",
        "{\n",
        "  \"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"...\"},\n",
        "    {\"role\": \"user\", \"content\": \"...\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "  ]\n",
        "}\n",
        "\n",
        "16385"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yYwG59M9Kwx1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system', 'content': '...'},\n",
              "  {'role': 'user', 'content': '...'},\n",
              "  {'role': 'assistant', 'content': '...'}]}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#EXAMPLE\n",
        "\n",
        "{\n",
        "  \"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"...\"},\n",
        "    {\"role\": \"user\", \"content\": \"...\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "  ]\n",
        "}\n",
        "#EXAMPLE\n",
        "\n",
        "{\n",
        "  \"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"...\"},\n",
        "    {\"role\": \"user\", \"content\": \"...\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "  ]\n",
        "}\n",
        "#EXAMPLE\n",
        "\n",
        "{\n",
        "  \"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"...\"},\n",
        "    {\"role\": \"user\", \"content\": \"...\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "  ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTXFcHMcKi4t"
      },
      "source": [
        "EPOCHS = forward+backward propagtion\n",
        "\n",
        "An epoch is one complete pass over the entire training dataset, during which the model computes the loss, applies the optimizer, and updates its weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FUrIzAqlCEhI"
      },
      "outputs": [],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 16385"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dSUnduUJK8cQ"
      },
      "outputs": [],
      "source": [
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "v7VtN28LBPRg"
      },
      "outputs": [],
      "source": [
        "#TARGET_EPOCHS = 3\n",
        "n_epochs = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "zawAJKYAOs1J"
      },
      "outputs": [],
      "source": [
        "# Warnings and tokens counts\n",
        "total_tokens_per_example  = []\n",
        "# assistant_tokens_per_example  = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "7sKTB9CpL2jK"
      },
      "outputs": [],
      "source": [
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHjrOkDHM23t"
      },
      "source": [
        "#### This function estimates how many tokens one training example (one conversation) will use.\n",
        "\n",
        "messages = a conversation\n",
        "(system + user + assistant)\n",
        "\n",
        "tokens_per_message = 3\n",
        "→ every message has extra hidden tokens\n",
        "\n",
        "tokens_per_name = 1\n",
        "→ if a message has a name, add 1 token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uwPZ-uLNnC6"
      },
      "source": [
        "##### [MSG_START]....[MSG_END]\n",
        "\n",
        "#### It matches OpenAI’s internal structure closely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "CAG5ACnLLMj4"
      },
      "outputs": [],
      "source": [
        "def num_tokens_from_messages(messages, tokens_per_message=2, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 2\n",
        "    return num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "zoU6hT7pVM0l"
      },
      "outputs": [],
      "source": [
        "for ex in data:\n",
        "    messages = ex[\"messages\"]\n",
        "    total_tokens_per_example.append(num_tokens_from_messages(messages))\n",
        "    # assistant_tokens_per_example.append(num_assistant_tokens_from_messages(messages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CNwNZyPCAb9",
        "outputId": "bb2ade85-0f2b-4d24-9683-e440dfa9a690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0 examples may be over the 16,385 token limit, if they are crossing the limit they will be truncated during fine-tuning\n"
          ]
        }
      ],
      "source": [
        "n_too_long = sum(l > 16385 for l in total_tokens_per_example)\n",
        "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, if they are crossing the limit they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "3pxEM-OYEAZy"
      },
      "outputs": [],
      "source": [
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in total_tokens_per_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDbInyZUfK24",
        "outputId": "6a4208cb-4711-47ab-daff-f1e949a578a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset has ~647 tokens that will be charged for during training\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR_IZ_sHZNoH",
        "outputId": "13d57a83-dba0-45b5-9095-753a0cfddccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "By default, you'll be charged for ~1941 tokens\n"
          ]
        }
      ],
      "source": [
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSjaIXzMZ-Zz"
      },
      "source": [
        "$1.50 / 1,000,000 = $0.0000015 per token\n",
        "2016 × 0.0000015 = $0.003024\n",
        "$0.003024 × 91 = ₹0.275184\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "X1tO9zA6Vcjv"
      },
      "outputs": [],
      "source": [
        "# TARGET_EXAMPLES = dataset rows × epochs\n",
        "# MIN_TARGET_EXAMPLES = 100\n",
        "# MAX_TARGET_EXAMPLES = 25000\n",
        "# n_train_examples = len(data)\n",
        "# if n_train_examples * n_epochs < MIN_TARGET_EXAMPLES:\n",
        "#     n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "# elif n_train_examples * n_epochs > MAX_TARGET_EXAMPLES:\n",
        "#     n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "# print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "# print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcxcjFTwEj2l"
      },
      "source": [
        "## Training starts from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geatetnrbm6s",
        "outputId": "be61f88a-7a64-4588-f2f7-346820c000cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x194355116a0>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZq7w1gdDRo",
        "outputId": "88ef53e0-a79e-4459-fe58-bbe5f04d2be5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-QHMzUJ9mEGrP28RHBtawuN', bytes=4239, created_at=1772191792, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.files.create(\n",
        "    file=open(\"data.jsonl\",\"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "kVxKyrS8dQXI"
      },
      "outputs": [],
      "source": [
        "files=client.files.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5djjZP3dYKA",
        "outputId": "cb55edfd-64f3-4eab-868b-3cbe832ae23f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FileObject](data=[FileObject(id='file-QHMzUJ9mEGrP28RHBtawuN', bytes=4239, created_at=1772191792, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-DXEtEkwwgTvdRKJ7yBPJtB', bytes=4239, created_at=1772190599, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)], has_more=False, object='list', first_id='file-QHMzUJ9mEGrP28RHBtawuN', last_id='file-DXEtEkwwgTvdRKJ7yBPJtB')"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzGaL3qePUI",
        "outputId": "5b181023-eba7-4b07-a7c8-75419268bd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file-QHMzUJ9mEGrP28RHBtawuN\n",
            "====================================================================================================\n",
            "fine-tune\n",
            "====================================================================================================\n",
            "FileObject(id='file-QHMzUJ9mEGrP28RHBtawuN', bytes=4239, created_at=1772191792, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
            "file-DXEtEkwwgTvdRKJ7yBPJtB\n",
            "====================================================================================================\n",
            "fine-tune\n",
            "====================================================================================================\n",
            "FileObject(id='file-DXEtEkwwgTvdRKJ7yBPJtB', bytes=4239, created_at=1772190599, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n"
          ]
        }
      ],
      "source": [
        "for file in files:\n",
        "  print(file.id)\n",
        "  print(100*\"=\")\n",
        "  print(file.purpose)\n",
        "  print(100*\"=\")\n",
        "  print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "qga9no3kfelP"
      },
      "outputs": [],
      "source": [
        "training_file_id=\"file-QHMzUJ9mEGrP28RHBtawuN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "KMFTymJkefV4"
      },
      "outputs": [],
      "source": [
        "suffix_name=\"final-finetune-model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWk2OiWke_io",
        "outputId": "2b2b0e80-280c-4cdf-bfb3-6110a20a7ed5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-KlwIg95d4L5P9ouiBWYFN01R', created_at=1772191759, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-s0OX7bgWGmnZGUCe5b8us8aE', result_files=[], seed=1869280486, status='validating_files', trained_tokens=None, training_file='file-DXEtEkwwgTvdRKJ7yBPJtB', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'))), user_provided_suffix='second-finetune-model', usage_metrics=None, shared_with_openai=False, eval_id=None, internal_worker_backend=None)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOUCCpwOVmJP",
        "outputId": "08ae0f89-b9a5-41f5-9f0c-322119d7bc4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-LKkhZ7wwixffPdr4AmNWJL6R', created_at=1772191852, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-s0OX7bgWGmnZGUCe5b8us8aE', result_files=[], seed=743229191, status='validating_files', trained_tokens=None, training_file='file-QHMzUJ9mEGrP28RHBtawuN', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3))), user_provided_suffix='final-finetune-model', usage_metrics=None, shared_with_openai=False, eval_id=None, internal_worker_backend=None)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "  training_file=training_file_id,\n",
        "  model=\"gpt-4o-2024-08-06\",\n",
        "  suffix=suffix_name,\n",
        "  method={\n",
        "    \"type\": \"supervised\",\n",
        "    \"supervised\": {\n",
        "      \"hyperparameters\": {\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate_multiplier\": 1.0,\n",
        "        \"n_epochs\": 3\n",
        "      }\n",
        "    }\n",
        "  }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nveZQ3ZjfZN4",
        "outputId": "9ecf3726-28cd-46de-abf9-4b268488e9f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-LKkhZ7wwixffPdr4AmNWJL6R', created_at=1772191852, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-s0OX7bgWGmnZGUCe5b8us8aE', result_files=[], seed=743229191, status='validating_files', trained_tokens=None, training_file='file-QHMzUJ9mEGrP28RHBtawuN', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3))), user_provided_suffix='final-finetune-model', usage_metrics=None, shared_with_openai=False, eval_id=None, internal_worker_backend=None), FineTuningJob(id='ftjob-KlwIg95d4L5P9ouiBWYFN01R', created_at=1772191759, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=10), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-s0OX7bgWGmnZGUCe5b8us8aE', result_files=[], seed=1869280486, status='running', trained_tokens=None, training_file='file-DXEtEkwwgTvdRKJ7yBPJtB', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=10))), user_provided_suffix='second-finetune-model', usage_metrics=None, shared_with_openai=False, eval_id=None, internal_worker_backend=None), FineTuningJob(id='ftjob-9BMPNrnLY65CcUzacAP7RZLc', created_at=1772191717, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-s0OX7bgWGmnZGUCe5b8us8aE', result_files=[], seed=2057815005, status='running', trained_tokens=None, training_file='file-DXEtEkwwgTvdRKJ7yBPJtB', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3))), user_provided_suffix='second-finetune-model', usage_metrics=None, shared_with_openai=False, eval_id=None, internal_worker_backend=None), FineTuningJob(id='ftjob-gv4c9jXZhuAevfaowbeNpHre', created_at=1772191537, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=1772191730, hyperparameters=Hyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3), model='gpt-4.1-nano-2025-04-14', object='fine_tuning.job', organization_id='org-s0OX7bgWGmnZGUCe5b8us8aE', result_files=[], seed=435334514, status='running', trained_tokens=None, training_file='file-DXEtEkwwgTvdRKJ7yBPJtB', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=16, learning_rate_multiplier=1.0, n_epochs=3))), user_provided_suffix='second-finetune-model', usage_metrics=None, shared_with_openai=False, eval_id=None, internal_worker_backend=None)], has_more=False, object='list')"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv4aN6QTf0Fn",
        "outputId": "e20b7101-aa40-4ebb-f912-7f8561266537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for job in client.fine_tuning.jobs.list():\n",
        "  print(job.fine_tuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ftjob-LKkhZ7wwixffPdr4AmNWJL6R cancelled None\n",
            "ftjob-KlwIg95d4L5P9ouiBWYFN01R cancelled None\n",
            "ftjob-9BMPNrnLY65CcUzacAP7RZLc cancelled None\n",
            "ftjob-gv4c9jXZhuAevfaowbeNpHre succeeded ft:gpt-4.1-nano-2025-04-14:grisha:second-finetune-model:DDqJXcPR\n"
          ]
        }
      ],
      "source": [
        "for job in client.fine_tuning.jobs.list(limit=20).data:\n",
        "    print(job.id, job.status, job.fine_tuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VatO8PWEiNoq",
        "outputId": "f4c35c68-b8e7-4898-86ae-685176a797f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for job in client.fine_tuning.jobs.list():\n",
        "  print(job.fine_tuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Pt-iSd-AgLi4",
        "outputId": "297512de-f156-4ef5-c3f9-f914d3baf42a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-DDqVpcoQseKZMlslU4EUUcaXOPIxl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The warranty details depend on the model and region. Please refer to the official website or warranty documentation provided with your device.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772192493, model='ft:gpt-4.1-nano-2025-04-14:grisha:second-finetune-model:DDqJXcPR', object='chat.completion', service_tier='default', system_fingerprint='fp_99264b0d92', usage=CompletionUsage(completion_tokens=24, prompt_tokens=71, total_tokens=95, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.chat.completions.create(\n",
        "    model=\"ft:gpt-4.1-nano-2025-04-14:grisha:second-finetune-model:DDqJXcPR\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a customer support agent for a smartphone company whose primary goal is to help users with issues they are experiencing with their smartphones. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to smartphones.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What warranty does a smartphone come with?\"\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "FmqZhocug_WU"
      },
      "outputs": [],
      "source": [
        "ans=client.chat.completions.create(\n",
        "    model=\"ft:gpt-4.1-nano-2025-04-14:grisha:second-finetune-model:DDqJXcPR\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a customer support agent for a smartphone company whose primary goal is to help users with issues they are experiencing with their smartphones. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to smartphones.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"what is the problem with my smartphone?\"\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvgmVbxlkxo",
        "outputId": "0488d78e-68ff-45dc-c150-361094dc5688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I cannot diagnose issues; please contact support for troubleshooting.\n"
          ]
        }
      ],
      "source": [
        "print(ans.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0Y-KgwXlycn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
